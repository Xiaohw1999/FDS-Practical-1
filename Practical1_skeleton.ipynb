{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "id1w7kwZVF3I"
   },
   "source": [
    "# Practical 1 : Implementation of Linear Regression (Ridge, Lasso)\n",
    "\n",
    "- Train a linear model\n",
    "    - using least squares method\n",
    "    - implement the model from scratch using NumPy \n",
    "    - Use learning curves plot to understand whether the linear moel is overfitting or underfitting\n",
    "- Train linear models with \n",
    "    - regularization (Ridge and Lasso)\n",
    "    - polynomial basis expansion\n",
    "    - use validation data to choose the hyperparameters\n",
    "    - scikit-learn\n",
    "    - Optional task: Use k-fold cross validation to choose the optimal hyperparameters (5 bonus points)\n",
    "\n",
    "We will use the following packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the work of Huiran Duan(21-737-507)and Xiaohui Wu(21-738-604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTZv9o5i4gy3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1-ZQWqTVPno"
   },
   "source": [
    "We will use the winequality dataset for this practical. The dataset is available here:\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine+Quality. \n",
    "In order to make it easier to import the dataset, the dataset has been converted to the numpy array format and shuffled, so that we can start the practical directly. The converted dataset is available on the OLAT page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzDL9RQiVaPY"
   },
   "source": [
    "The dataset has two files. We’ll focus on the white wine data, which is the larger dataset. The following code loads the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1596436129238,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "NYkwbebUVO_i",
    "outputId": "80ed8916-85c3-4564-cda8-d8a8f36aaa1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a (4898, 11) matrix, which contains 4898 data records and 11 features.\n",
      "y is a 4898-dimentional vector, which stores the corresponding labels of the data records in X\n",
      "[[ 7.6   0.24  0.44 ...  3.06  0.37 11.6 ]\n",
      " [ 6.9   0.41  0.33 ...  3.2   0.52  9.4 ]\n",
      " [10.    0.2   0.39 ...  3.    0.42 10.4 ]\n",
      " ...\n",
      " [ 6.3   0.48  0.04 ...  3.24  0.36  9.6 ]\n",
      " [ 5.8   0.13  0.22 ...  3.32  0.42 11.7 ]\n",
      " [ 7.8   0.32  0.33 ...  3.07  0.58  9.6 ]]\n"
     ]
    }
   ],
   "source": [
    "# load the white wine dataset\n",
    "# X is the feature matrix that stores the feature values of the data records\n",
    "# y is the label vector that stores the labels of the data records\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))\n",
    "\n",
    "# check the size of the data\n",
    "print(\"X is a {} matrix, which contains {} data records and {} features.\".format(X.shape, X.shape[0], X.shape[1]))\n",
    "print(\"y is a {}-dimentional vector, which stores the corresponding labels of the data records in X\".format(y.shape[0]))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGuNg0KbWN0z"
   },
   "source": [
    "We next split the data into training data and test data. \n",
    "In practice, we should sample randomly 80% of the data as training data and the rest as the test data. . \n",
    "However, in order to get consistent results, we use the first 80% of the data as training\n",
    "data and the remaining as the test data. \n",
    "To achieve this split, we define the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1596436129239,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "6ZqbBa8bWNYg",
    "outputId": "da274c4e-c3ed-4ac0-8442-27befcf26f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3918, 11)\n",
      "Shape of y_train: (3918,)\n",
      "Shape of X_test: (980, 11)\n",
      "Shape of y_test: (980,)\n"
     ]
    }
   ],
   "source": [
    "# The function splits the dataset into training data and testing data.\n",
    "# The parameter split_coeff is a percentage value such that\n",
    "# the first split_coeff of the dataset goes to the training dataset \n",
    "# and the remaining data goes to the test dataset.\n",
    "def split_data(X, y, split_coeff):\n",
    "    N, _ = X.shape # get the number of records (rows)\n",
    "    train_size = int(split_coeff * N) # use the first split_coeff of the data as the training data\n",
    "    X_train = X[:train_size] # the first training_size records\n",
    "    y_train = y[:train_size]\n",
    "    X_test = X[train_size:] # the last test_size records\n",
    "    y_test = y[train_size:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, 0.8) # split the data with split_coeff=0.8\n",
    "\n",
    "# check the size of the splitted dataset\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2yKNR49Wkn8"
   },
   "source": [
    "## Understanding What We’re Predicting\n",
    "\n",
    "Let’s first check\n",
    "the distribution of the y-values in the training data. \n",
    "You will find that the values are integers between 3 and 9 indicating the quality of the wine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PMpsZNSWthB"
   },
   "source": [
    "### **Task 1**\n",
    "Make a bar chart showing the distribution of y-values in the training data. You will find that the y-values are integers from 3 to 9, which indicate the quality of the wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "4L_JDK3dWrsR",
    "outputId": "71b22bf6-77ce-4bd6-d5b1-61f633923144"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title\n",
    "# Task 1: \n",
    "# the function takes the y-values in the training data as the input and makes the bar chart. \n",
    "# Hint: Your function should make a bar chart looks like the bar chart below.\n",
    "def plot_bar_chart_score(y_train):\n",
    "    dict_y = {} \n",
    "    for item in y_train:\n",
    "        dict_y[item] = dict_y.get(item, 0) + 1 # get the number of wines of each score, return to a dict\n",
    "    plt.bar(dict_y.keys(), dict_y.values())\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Number of wines')\n",
    "    plt.title('Distriibution of score of wines')\n",
    "\n",
    "plot_bar_chart_score(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxjlElni2FcH"
   },
   "source": [
    "### **Task 2** \n",
    "This task is to build a trivial predictor, which always returns the mean of the y-values of the training data. We consider the trivial model as a baseline. The linear regression models we build later should perform better than this trivial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "-V3xFYexX1lt",
    "outputId": "5e57738e-87d5-408c-f1bf-9df66a175f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of y on the training label values is 5.878764675855028\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "# Task 2: implement the trivial predictor\n",
    "# The function computes the average value of y on the training label values\n",
    "def compute_average(y_train):\n",
    "    avg_y_trian = np.mean(y_train)\n",
    "    return avg_y_trian\n",
    "\n",
    "y_train_avg = compute_average(y_train)\n",
    "print(\"Average of y on the training label values is {}\".format(y_train_avg))\n",
    "\n",
    "# The trivial predictor returns the average value.\n",
    "def trivial_predictor(X_test, y_train_avg):\n",
    "    return y_train_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x531Q_SxXV14"
   },
   "source": [
    "### **Task 3**\n",
    "We next evaluate the trivial predictor on the training data and test data. \n",
    "We use mean squared error (MSE) to measure the performance of the predictor.\n",
    "The task is to implement a function that reports the mean squared error of the given predictor on the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "mV8l6Ci9YlgL",
    "outputId": "f57858dc-d0fc-40fe-dbf7-c652d2f8fddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trivial Predictor\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.7768\n",
      "MSE (Testing)  = 0.8139\n"
     ]
    }
   ],
   "source": [
    "# We next test our trivial predictor on the training data and test data. \n",
    "# Implement a function that can report the mean squared error \n",
    "# of a predictor on the given data\n",
    "# Input: data and predictor\n",
    "# Output: mean squared error of the predictor on the given data\n",
    "def test_predictor(X, y, predictor: callable=None):\n",
    "    # Apply the predictor to each row of the matrix X to get the predictions\n",
    "    y_predicted = np.apply_along_axis(predictor, 1, X)\n",
    "    mse = np.dot((y-y_predicted).T, (y-y_predicted))/(len(y))\n",
    "    return mse\n",
    "\n",
    "# use the function test_predictor to test the trivial predictor\n",
    "# we use the lambda function here to pass the function trivial predictor to the function test_predictor.\n",
    "mse_trivial_predictor_train = test_predictor(X_train, y_train, lambda x: trivial_predictor(x, y_train_avg))\n",
    "mse_trivial_predictor_test = test_predictor(X_test, y_test, lambda x: trivial_predictor(x, y_train_avg))\n",
    "\n",
    "# Report the result\n",
    "print('Trivial Predictor')\n",
    "print('--------------------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_trivial_predictor_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_trivial_predictor_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geiyM1Nea0az"
   },
   "source": [
    "## Train the Linear Model Using Least Squares Method\n",
    "\n",
    "Let us train a linear model on the training data and then check its MSE. \n",
    "We use the closed form solution of the least squares estimate to get the parameters of the linear model. \n",
    "The linear model should perform better than the trivial predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSEwFGp_bqAI"
   },
   "source": [
    "### **Task 4**\n",
    "Before training the model, we need to standardize the data, i.e., transform the data so that every feature has mean 0 and variance 1. \n",
    "\n",
    "https://en.wikipedia.org/wiki/Standard_score\n",
    "\n",
    "We first standardize the training data. \n",
    "Then we apply the same transformation to the test data, i.e. standardize the test data using the means and the standard deviations of the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1596436129241,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "trjwkcgybhDH",
    "outputId": "d87a4635-354f-47e2-947a-e843f027e4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_std: (3918, 11)\n",
      "Mean: [6.85427514e+00 2.78390761e-01 3.34892802e-01 6.42623788e+00\n",
      " 4.58213374e-02 3.53263144e+01 1.38513272e+02 9.94040729e-01\n",
      " 3.18647524e+00 4.89055641e-01 1.05115799e+01]\n",
      "Standard deviation: [8.39100902e-01 9.95630176e-02 1.24249975e-01 5.06377532e+00\n",
      " 2.16660282e-02 1.71004677e+01 4.23956179e+01 2.97972269e-03\n",
      " 1.49949475e-01 1.12992053e-01 1.22536544e+00]\n"
     ]
    }
   ],
   "source": [
    "# The task is to implement a function that can standardize the data and returns the mean and std of the data.\n",
    "# Input: training data\n",
    "# Output: standardize training data, standard deviations and means\n",
    "\n",
    "def standardize_data(X):\n",
    "    # TODO: compute the means and standard deviations of the data, and standardize the data\n",
    "    mean = np.mean(X, axis = 0) # standardize by column\n",
    "    std = np.std(X, axis = 0)\n",
    "    X_std = (X-mean)/std\n",
    "    return X_std, mean, std\n",
    "\n",
    "# Standardize the training data and store the means and the stds \n",
    "X_train_std, X_train_mean, X_train_std_div = standardize_data(X_train)\n",
    "print(\"X_train_std:\", X_train_std.shape)\n",
    "print(\"Mean:\", X_train_mean)\n",
    "print(\"Standard deviation:\", X_train_std_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1596436129242,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "RjzbA5JpM759",
    "outputId": "ff594788-2fdd-419c-98fa-beac6a53cfc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18385767  0.61879643  1.65076248 ... -0.97683064  0.62787034\n",
      "  -1.39679138]\n",
      " [ 1.24624447  0.51835753 -0.44179327 ... -0.24325022 -0.96516204\n",
      "  -1.39679138]\n",
      " [ 0.41201822  0.31747972  0.12158713 ... -0.30993935  0.36236495\n",
      "  -0.66231661]\n",
      " ...\n",
      " [-0.66055839  2.02494103 -2.37338318 ...  0.35695195 -1.14216564\n",
      "  -0.74392492]\n",
      " [-1.25643428 -1.49042048 -0.92469075 ...  0.89046499 -0.61115484\n",
      "   0.96984954]\n",
      " [ 1.12706929  0.41791862 -0.0393787  ... -0.77676326  0.80487394\n",
      "  -0.74392492]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Standardize the test data using the means and standrad deviations of the training data\n",
    "\n",
    "X_test_std = (X_test-X_train_mean)/X_train_std_div\n",
    "print(X_test_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRPPA6HMbNOr"
   },
   "source": [
    "### **Task 5**\n",
    "We have standardized X-values. Do we need to standardize the y-values? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9he5QMmfqL3_"
   },
   "source": [
    "NO, it does not force us to standardize the y_values.\n",
    "\n",
    "When do we need to standardize the data? The scale of some features and the magnitude of the values are different, then their influence on y_values will be different, and through normalization, it can make different features have the same scale. Briefly speeking, When the scales (units) of features in different dimensions of the original data are inconsistent, standardization steps are required to preprocess the data.\n",
    "\n",
    "The arguments to standardize X in this cases do not apply to y_values, but if we want you can standardize y_values too, it may do no harm, but can complicate interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vT4_Sl42bxmD"
   },
   "source": [
    "### **Task 6**\n",
    "Let's now train the linear model using the least-squares method. \n",
    "We need to add the bias term to the matrix X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1596436129242,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "A4JtLr6pdJV7",
    "outputId": "dfd57312-284f-4ce9-820b-4fdbdfbec8c4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [ 5.87876468e+00  5.70365710e-02 -1.83384219e-01 -4.04067444e-03\n",
      "  4.09097280e-01 -8.17517111e-03  5.92929519e-02 -3.56633675e-03\n",
      " -4.36936781e-01  9.87381160e-02  6.53325059e-02  2.42495455e-01] (12,)\n"
     ]
    }
   ],
   "source": [
    "# The task is to implement the function that adds a column of ones to the front of the input matrix\n",
    "def expand_with_ones(X):\n",
    "    # TODO: add a column of ones to the front of the input matrix\n",
    "    row_X = X.shape[0]\n",
    "    X_1 = np.ones(row_X)\n",
    "    X = np.c_[X_1, X]\n",
    "    X_out = X\n",
    "    return X_out\n",
    "\n",
    "# Train the linear model using the least-squares method\n",
    "# The task is to implement the function that computes the parameters\n",
    "def least_squares_compute_parameters(X_input, y):\n",
    "    # add the bias column to the data\n",
    "    X = expand_with_ones(X_input)\n",
    "\n",
    "    # TODO: compute the parameters based on the expanded X and y using the least-squares method\n",
    "    \n",
    "    learningRate = 0.01\n",
    "    loopnum = 100000\n",
    "    w = np.ones(X.shape[1])\n",
    "    # b = np.array([1])\n",
    "    \n",
    "    for num in range(loopnum):\n",
    "        y_hat = np.dot(X, w)\n",
    "        # y_hat = np.dot(X, w) + b\n",
    "        loss = np.dot((y-y_hat).T, (y-y_hat))/(len(y))\n",
    "        w_gradient = -(1/X.shape[0])*np.dot((y-y_hat).T,X)\n",
    "        # b_gradient = -1*np.dot((y-y_hat).T,np.ones(shape=[X.shape[0],1]))/X.shape[0]\n",
    "        w = w-learningRate*w_gradient\n",
    "        # b=b-learningRate*b_gradient\n",
    "#         if num%50 == 0:\n",
    "#             print(loss)     \n",
    "    return w\n",
    "\n",
    "# Apply the function to train the linear model\n",
    "w = least_squares_compute_parameters(X_train_std, y_train) \n",
    "print(\"w:\", w, w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lasj_1PpeZib"
   },
   "source": [
    "After computing the parameters,\n",
    "we can build the linear model predictor.\n",
    "The predictor takes as input the computed parameters and the data, and predicts the labels for the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb-hNagxc3Wj"
   },
   "outputs": [],
   "source": [
    "# Implement the linear model predictor\n",
    "# Input: test data and parameters\n",
    "# Output: predicted values\n",
    "def linear_model_predictor(X, w):\n",
    "    # TODO: predict the labels for the input data\n",
    "    y_predict = np.dot(X, w)    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFOYpwbufz7J"
   },
   "source": [
    "We can now evaluate our linear model predictor on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1596436129243,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "LuHHmn2RB55j",
    "outputId": "b6cb4556-2618-419a-a082-214f2e6ecb5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error is 0.5607292042286587\n"
     ]
    }
   ],
   "source": [
    "# use the function test_predictor to evaluate the linear model predictor\n",
    "mse_linear_model_predictor = test_predictor(expand_with_ones(X_test_std), y_test, lambda x: linear_model_predictor(x, w))\n",
    "print(\"Mean squared error is {}\".format(mse_linear_model_predictor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqj4HKAihF7Q"
   },
   "source": [
    "## Learning Curves\n",
    "\n",
    "Let us check if the linear model is overfitting or underfitting. Since the dataset is somewhat large and there are only 11 features, the model shouldn't be overfitting. \n",
    "To check it, we need to check the learning curves, i.e. how the performance of the model changes when it is trained with increasingly more data. \n",
    "We train the model on the increasingly more data ([20, 40, ..., 600] data records), and evaluate the model by computing the MSE of the model on both the training data and the test data. \n",
    "We use the collected MSE to build the learning curves plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNf11kurCgKF"
   },
   "source": [
    "### **Task 7** \n",
    "\n",
    "Let's first implement a function that comprises what we have implemented above. \n",
    "The function takes as inputs the data and the split coefficient, and\n",
    "1. standardizes the data,\n",
    "2. trains the linear model, and\n",
    "3. reports the mse of the linear model predictor on both training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1596436129244,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "UcGRQBrEb106",
    "outputId": "179c5ec0-ee87-4c4b-a02b-d97d55862e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "-----------------------\n",
      "\n",
      "MSE (Training) = 0.5640\n",
      "MSE (Testing)  = 0.5607\n"
     ]
    }
   ],
   "source": [
    "# Input: training data and test data\n",
    "# Output: mse of the linear model predictor on both the training and test data\n",
    "def train_and_test(X_train, y_train, X_test, y_test):\n",
    "    # TODO: implement the function \n",
    "    X_tr, X_tr_mean, X_tr_std = standardize_data(X_train)\n",
    "    X_te = (X_test-X_tr_mean)/X_tr_std\n",
    "    w_tr = least_squares_compute_parameters(X_tr, y_train)\n",
    "    mse_train = test_predictor(expand_with_ones(X_tr), y_train, lambda x: linear_model_predictor(x, w_tr))\n",
    "    mse_test = test_predictor(expand_with_ones(X_te), y_test, lambda x: linear_model_predictor(x, w_tr))\n",
    "    # Hints: use the functions you have implemented\n",
    "    return mse_train, mse_test\n",
    "\n",
    "\n",
    "mse_train, mse_test = train_and_test(X_train, y_train, X_test, y_test)\n",
    "print('Linear Model')\n",
    "print('-----------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTJw_BrzhRwi"
   },
   "source": [
    "We are now ready to report the learning curves.\n",
    "The task is to train the linear model on the increasingly more data ([20, 40, ..., 600] data records)\n",
    "and store the MSE of the trained model on the training data and the test data in the lists `mse_train_v` and `mse_test`, respectively. \n",
    "We have provided the code for generating the learning curves from `mse_train_v` and `mse_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1747,
     "status": "ok",
     "timestamp": 1596436129644,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "jDsdh4T3hcIU",
    "outputId": "621c4890-1c55-4e9b-f28f-33d60907d8b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_train_v = []\n",
    "mse_test_v = []\n",
    "\n",
    "TRAINING_SIZE_MAX = 601\n",
    "TRAINING_SIZE_MIN = 20\n",
    "\n",
    "# compute the MSE over data with sizes from TRAINING_SIZE_MIN to TRAINING_SIZE_MAX with increasing step 20\n",
    "for train_size in range(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20):\n",
    "    # TODO: \n",
    "    #   1. use the first train_size data records from the X_train and y_train as the training data\n",
    "    #   2. train and compute the MSE on both training and test data using the train_and_test function\n",
    "    #   3. add the computed MSE to the lists mse_train_v and mse_test_v\n",
    "    x_train_v = X_train[:train_size]\n",
    "    y_train_v = y_train[:train_size]\n",
    "    mse_train, mse_test = train_and_test(x_train_v, y_train_v, X_test, y_test)\n",
    "    mse_train_v.append(mse_train)\n",
    "    mse_test_v.append(mse_test)\n",
    "\n",
    "\n",
    "# The below code generates the learning curves plot\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20), mse_train_v, 'r--', label=\"Training Error\")\n",
    "plt.plot(np.arange(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20), mse_test_v, 'b-', label=\"Test Error\")\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 8**\n",
    "Explain whether you think the model is underfitting or not and how much data you need before getting the optimal test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9A9VqDTzOdfd"
   },
   "source": [
    "My model is NOT underfitting or overfitting. \n",
    "Because we know that \"high bias\" means underfitting and \"low bias high variance\" means overfitting.\n",
    "However,the mean square error of the training and test data meet and stay at a more stable position.\n",
    "We can find the traning error reach the bottom at 450 and test error still remained stable, that means it is hard to reduce the MSE by adding more data after the dataset size is around 450.\n",
    "So we need about 450 dataset size before getting the optimal test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djpsaTu_kK3T"
   },
   "source": [
    "## Polynomial Basis Expansion and Regularisation\n",
    "\n",
    "In this part, we will try to improve the linear model by basis expansion and regularisation. \n",
    "\n",
    "The task is to \n",
    "1. apply the degree 2 basis expansion to the data, \n",
    "2. build the Ridge and Lasso models using scikit-learn, and\n",
    "3. perform hyperparameter optimization to find the optimal hyperparameter lambda. \n",
    "\n",
    "For the hyperparameter optimization, you should set the last 20% of the training data for the purpose of validation and \n",
    "try lambda values [10^-4, 10^-3, 10^-2, 10^-1, 1, 10, 100]. \n",
    "\n",
    "\n",
    "We will use the scikit-learn package. You can import other scikit-learn packages if you think they are useful. Read the documentation available here: http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TM0nkNbkhfM"
   },
   "outputs": [],
   "source": [
    "# import the preprocessing libs for standarization and basis expansion\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n",
    "\n",
    "# Ridge and Lasso linear model\n",
    "from sklearn.linear_model import Ridge, Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCwBPuOXlRF7"
   },
   "source": [
    "### **Task 9**\n",
    "Let's implement the function for expanding the basis of the dataset. \n",
    "\n",
    "Hints: use `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50azFolql1qA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 7.6000e+00 2.4000e-01 ... 1.3690e-01 4.2920e+00 1.3456e+02]\n",
      " [1.0000e+00 6.9000e+00 4.1000e-01 ... 2.7040e-01 4.8880e+00 8.8360e+01]\n",
      " [1.0000e+00 1.0000e+01 2.0000e-01 ... 1.7640e-01 4.3680e+00 1.0816e+02]\n",
      " ...\n",
      " [1.0000e+00 6.3000e+00 4.8000e-01 ... 1.2960e-01 3.4560e+00 9.2160e+01]\n",
      " [1.0000e+00 5.8000e+00 1.3000e-01 ... 1.7640e-01 4.9140e+00 1.3689e+02]\n",
      " [1.0000e+00 7.8000e+00 3.2000e-01 ... 3.3640e-01 5.5680e+00 9.2160e+01]]\n"
     ]
    }
   ],
   "source": [
    "def expand_basis(X, degree):\n",
    "    # TODO: expand the basis of X for the input degree\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X = poly.fit_transform(X)\n",
    "    # Hints: use the function PolynomialFeatures\n",
    "    return X\n",
    "\n",
    "print(expand_basis(X, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jwkPevimQri"
   },
   "source": [
    "### **Task 10**\n",
    "We need to expand and standardize the the data,\n",
    "and prepare the training, test and validation data on the expanded data. \n",
    "You should set the last 20% of the training data as the validation data.\n",
    "\n",
    "Hints: use `StandardScaler` and `std_scaler` to standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQCq4G9YmW7w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3918, 78) (3134, 78) (784, 78) (980, 78)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(X, y, degree):\n",
    "    # TODO: the training, test and validation data using the expanded dataset.\n",
    "    \n",
    "    # Hints: follow the steps\n",
    "    \n",
    "    # 1. split the data (X, y) into training data (X_train, y_train) and test data (X_test, y_test)\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, 0.8)\n",
    "\n",
    "    # 2. standardize the training data and do the same transformation to the test data\n",
    "    s = StandardScaler()\n",
    "    s.fit(X_train)\n",
    "    X_train = s.transform(X_train)\n",
    "    s_mean = s.mean_\n",
    "    s_scale = s.scale_\n",
    "    X_test = (X_test-s_mean)/s_scale\n",
    "\n",
    "    # 3. expand the basis of the training data and test data\n",
    "    X_train = expand_basis(X_train, degree)\n",
    "    X_test = expand_basis(X_test, degree)\n",
    " \n",
    "    # 4. standardize the training data again and do the same transformation to the test data\n",
    "    \n",
    "    s.fit(X_train)\n",
    "    X_train = s.transform(X_train)\n",
    "    s_mean = s.mean_\n",
    "    s_scale = s.scale_\n",
    "    X_test = (X_test-s_mean)/s_scale\n",
    "    \n",
    "    # 5. split the expanded training data into training data (X_train_n, y_train_n) and validation data (X_train_v, y_train_v)\n",
    "    X_train_n, y_train_n, X_train_v, y_train_v = split_data(X_train, y_train, 0.8)\n",
    "\n",
    "    \n",
    "    # 6. standardize the training data and do the same transformation to the validation data\n",
    "    s.fit(X_train_n)\n",
    "    s_mean = s.mean_\n",
    "    s_scale = s.scale_\n",
    "    \n",
    "    X_train_n = s.transform(X_train_n)\n",
    "    X_train_v = (X_train_v-s_mean)/s_scale\n",
    "\n",
    "    return X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test = prepare_data(X, y, 2) # here we expand the dataset with degree 2\n",
    "print(np.shape(X_train), np.shape(X_train_n), np.shape(X_train_v), np.shape(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why standardisation is required before basis expansion?**\n",
    "\n",
    "Assume we have a dataset with two features x1 and x2, where x1 has a small scale while x2 has a large scale. When we perform basis expansion, we  get a new feature x1x2. Since x2 has a larger scale than x1, it is likely x2 will contribute more to the value of the new feature x1x2, which means a bias is introduce here. \n",
    "The correct way is to standardise the features before the basis expansion. In this case x1 and x2 have the same scale, so they contribute same to the new feature x1x2, i.e. no bias is introduced. \n",
    "\n",
    "\n",
    "**Why standardise the training data in step 5?**\n",
    "\n",
    "Ridge and Lasso regularisation require the data to have mean of 0 and standard deviation of 1. However, after the basis expansion and splitting in step 4, the training data might not have the desired distribution, so we need to perform the standardisation on the training data. \n",
    "\n",
    " \n",
    "**Why not standardise both training and validation data together?**\n",
    "\n",
    "When we use validation data to chose the hyperparameters, we treat the validation data like the test data -- we should not assume we can access these data. So we should standardise the training data and perform the same operation to the validation data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3BxxtM3nghU"
   },
   "source": [
    "### **Task 11**\n",
    "We have prepared the training data and the validation data. We can now choose the hyperparameter lambda for Ridge and Lasso using the validation data. \n",
    "We use the Ridge and Lasso models from scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "We train Ridge or Lasso models with different lambda values and check their performance on the validation data.\n",
    "The lambda value that results the best performance is then the optimal lambda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3266,
     "status": "ok",
     "timestamp": 1596436131187,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "SvXcAGW1oHq1",
    "outputId": "25a38d1f-013f-4b0a-9cbb-3f08b68c0371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge lambda: 1\n",
      "Lasso lambda: 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The function takes the training and validation data as inputs, and \n",
    "# returns the lambda value that results the minimal mse\n",
    "# We use is_ridge to indicate which the model is considered.\n",
    "# is_ridge = True indicates Ridge while is_ridge = False indicates Lasso\n",
    "def choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, is_ridge: bool):\n",
    "    mse_arr = []\n",
    "    lam_arr = []\n",
    "\n",
    "    # Try lambda values from 10^-4 to 10^3. \n",
    "    # Record the mse and the lambda values in mse_arr and lam_arr\n",
    "    \n",
    "    for pow_lam in range(-4, 3):\n",
    "        lam = 10 ** pow_lam\n",
    "        if is_ridge is True:\n",
    "            clif = Ridge(alpha = lam)\n",
    "            clif.fit(X_train_n, y_train_n)\n",
    "            y_predicted = clif.predict(X_train_v)\n",
    "        elif is_ridge is False:\n",
    "            clif = Lasso(alpha = lam)\n",
    "            clif.fit(X_train_n, y_train_n)\n",
    "            y_predicted = clif.predict(X_train_v)\n",
    "        mse = np.dot((y_train_v-y_predicted).T, (y_train_v-y_predicted))/(len(y_train_v)) # compute the mse for this lam\n",
    "        mse_arr.append(mse) \n",
    "        lam_arr.append(lam)\n",
    "\n",
    "\n",
    "    # get the index of the lambda value that has the minimal use\n",
    "    lambda_idx_min = np.argmin(np.array(mse_arr))\n",
    "\n",
    "    # plot of the lambda values and their mse\n",
    "    plt.figure()\n",
    "    plt.semilogx(lam_arr, mse_arr)\n",
    "\n",
    "    # return the optimal lambda value\n",
    "    return lam_arr[lambda_idx_min]\n",
    "\n",
    "# call the function to choose the lambda for Ridge and Lasso\n",
    "lam_ridge = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, True)\n",
    "lam_lasso = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, False)\n",
    "\n",
    "print(\"Ridge lambda:\", lam_ridge)\n",
    "print(\"Lasso lambda:\", lam_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAuX0uU5k9qD"
   },
   "source": [
    "### **Task 12**:\n",
    "Once you’ve obtained the optimal lambdas for Ridge and Lasso, train these models using these lambdas on the full training data. Then report\n",
    "the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3259,
     "status": "ok",
     "timestamp": 1596436131187,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "VmwHESkg77zK",
    "outputId": "9bb9c1cf-1649-40e6-9162-2244525d9446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ridge Regression with using degree 2 polynomial expansion and lambda = 1.0000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.4952\n",
      "MSE (Testing)  = 0.5126\n",
      "\n",
      "\n",
      "For Lasso with using degree 2 polynomial expansion and lambda = 0.0010\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.4966\n",
      "MSE (Testing)  = 0.5101\n"
     ]
    }
   ],
   "source": [
    "# TODO: train the Ridge and Lasso models using the optimal parameters, and\n",
    "#       report their MSE\n",
    "\n",
    "Ridge_tr = Ridge(alpha = 1)\n",
    "Ridge_tr.fit(X_train, y_train)\n",
    "y_tr_ri = Ridge_tr.predict(X_train)\n",
    "\n",
    "Ridge_te = Ridge(alpha = 1)\n",
    "Ridge_te.fit(X_train, y_train)\n",
    "y_te_ri = Ridge_te.predict(X_test)\n",
    "\n",
    "Lasso_tr = Lasso(alpha = 0.001)\n",
    "Lasso_tr.fit(X_train, y_train)\n",
    "y_tr_la = Lasso_tr.predict(X_train)\n",
    "\n",
    "Lasso_te = Lasso(alpha = 0.001)\n",
    "Lasso_te.fit(X_train, y_train)\n",
    "y_te_la = Lasso_te.predict(X_test)\n",
    "\n",
    "# Hints: train these models on the full training data\n",
    "mse_ridge_train = np.dot((y_train-y_tr_ri).T, (y_train-y_tr_ri))/(len(y_train))\n",
    "mse_ridge_test = np.dot((y_test-y_te_ri).T, (y_test-y_te_ri))/(len(y_test))\n",
    "mse_lasso_train = np.dot((y_train-y_tr_la).T, (y_train-y_tr_la))/(len(y_train))\n",
    "mse_lasso_test = np.dot((y_test-y_te_la).T, (y_test-y_te_la))/(len(y_test))\n",
    "\n",
    "\n",
    "# Report the result\n",
    "print('For Ridge Regression with using degree %d polynomial expansion and lambda = %.4f' % (2, lam_ridge))\n",
    "print('--------------------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_ridge_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_ridge_test)\n",
    "\n",
    "print('\\n\\nFor Lasso with using degree %d polynomial expansion and lambda = %.4f' % (2, lam_lasso))\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_lasso_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_lasso_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Os9tKKLd8gMU"
   },
   "source": [
    "## Optional: Try Larger Degrees using K-fold Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfqRAlv1PBXi"
   },
   "source": [
    "### **Task 13**\n",
    "This is an optional task, which worths 5 bonus poitns.\n",
    "\n",
    "The task is to try basis expansions with higher degrees (up to degree 4) and find the degree that results the best performance. \n",
    "Instead of always using the same validation set, you should use k-fold cross validation to find the optimal hyperparameters. \n",
    "You should report the optimal hyperparameters (the basis expansion degree and the lambdas) and the MSE of the Ridge and Lasso when you apply the optimal hyperparameters. \n",
    "\n",
    "Hints: Use `KFold` to do this automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cp\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, split_coeff):\n",
    "    N, _ = X.shape # get the number of records (rows)\n",
    "    train_size = int(split_coeff * N) # use the first split_coeff of the data as the training data\n",
    "    X_train = X[:train_size] # the first training_size records\n",
    "    y_train = y[:train_size]\n",
    "    X_test = X[train_size:] # the last test_size records\n",
    "    y_test = y[train_size:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# expand basis, degree = 1,2,3,4\n",
    "def expand_basis(X, degree):\n",
    "    # TODO: expand the basis of X for the input degree\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X = poly.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "# use standardscaler to sandardize data\n",
    "def standardize(X_train, X_test):\n",
    "    s = StandardScaler()\n",
    "    s.fit(X_train)\n",
    "    X_train = s.transform(X_train)\n",
    "    s_mean = s.mean_\n",
    "    s_scale = s.scale_\n",
    "    X_test = (X_test-s_mean)/s_scale\n",
    "    return X_train, X_test\n",
    "\n",
    "# use KFold to divide train into training and validation\n",
    "def Kfold(X,n):\n",
    "    X_train_n = []\n",
    "    X_train_v = []\n",
    "    y_train_n = []\n",
    "    y_train_v = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train_index , test_index in kf.split(X):  \n",
    "        X_train_n.append(X[train_index])\n",
    "        X_train_v.append(X[test_index])\n",
    "        y_train_n.append(y[train_index])\n",
    "        y_train_v.append(y[test_index])\n",
    "    return X_train_n, X_train_v, y_train_n, y_train_v\n",
    "\n",
    "def data_prepare(X, y, n, degree):\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, 0.8)\n",
    "    X_train, X_test = standardize(X_train, X_test)\n",
    "    X_train = expand_basis(X_train, degree)\n",
    "    X_test = expand_basis(X_test, degree)\n",
    "    X_train_n, X_train_v, y_train_n, y_train_v = Kfold(X_train, n)\n",
    "    for i in range(n):\n",
    "        X_train_n[i], X_train_v[i] = standardize(X_train_n[i], X_train_v[i])\n",
    "        i += 1\n",
    "    return X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X,y = input dataset, n = proportion of training and validation dataset, degree = demension of expandsion\n",
    "\n",
    "def choose_hyper_param(X, y, n, degree, lam_min, lam_max, is_ridge: bool, is_plot: bool):\n",
    "\n",
    "    X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test = data_prepare(X, y, n, degree)\n",
    "    lam_arr = []\n",
    "    mse_average_arr = []\n",
    "        \n",
    "    for pow_lam in range(lam_min, lam_max):\n",
    "        lam = 10 ** pow_lam\n",
    "        mse_arr = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            if is_ridge is True:\n",
    "                clif = Ridge(alpha = lam)\n",
    "                clif.fit(X_train_n[i], y_train_n[i])\n",
    "                y_predicted = clif.predict(X_train_v[i])\n",
    "                mse = np.dot((y_train_v[i]-y_predicted).T, (y_train_v[i]-y_predicted))/(len(y_train_v[i])) # compute the mse for this lam\n",
    "                mse_arr.append(mse)\n",
    "                \n",
    "            elif is_ridge is False:\n",
    "                clif = Lasso(alpha = lam)\n",
    "                clif.fit(X_train_n[i], y_train_n[i])\n",
    "                y_predicted = clif.predict(X_train_v[i])\n",
    "                mse = np.dot((y_train_v[i]-y_predicted).T, (y_train_v[i]-y_predicted))/(len(y_train_v[i])) # compute the mse for this lam\n",
    "                mse_arr.append(mse) \n",
    "                \n",
    "        mse_average_arr.append(np.mean(mse_arr))\n",
    "        lam_arr.append(lam)\n",
    "\n",
    "    # get the index of the lambda value that has the minimal use\n",
    "    lambda_idx_min = np.argmin(np.array(mse_average_arr))\n",
    "    mse_idx_min = np.min(mse_average_arr)\n",
    "\n",
    "    # plot of the lambda values and their mse\n",
    "    if is_plot is True:\n",
    "        if is_ridge is True:\n",
    "            plt.figure()\n",
    "            plt.semilogx(lam_arr, mse_average_arr)\n",
    "            plt.title('Ridge')\n",
    "        elif is_ridge is False:\n",
    "            plt.figure()\n",
    "            plt.semilogx(lam_arr, mse_average_arr)\n",
    "            plt.title('Lasso')\n",
    "                \n",
    "    # return the optimal lambda value\n",
    "    return lam_arr[lambda_idx_min], mse_idx_min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choose_degree(X, y, n, degree, lam_min, lam_max):\n",
    "    mse_ridge_list = []\n",
    "    lamda_ridge_list = []\n",
    "    mse_lasso_list = []\n",
    "    lamda_lasso_list = []\n",
    "    \n",
    "    for i in range(degree):\n",
    "        min_lam_ridge, min_mse_ridge = choose_hyper_param(X, y, n, i+1, lam_min, lam_max, True, False)\n",
    "        min_lam_lasso, min_mse_lasso = choose_hyper_param(X, y, n, i+1, lam_min, lam_max, False, False)\n",
    "        \n",
    "        mse_ridge_list.append(min_mse_ridge)\n",
    "        lamda_ridge_list.append(min_lam_ridge)\n",
    "        mse_lasso_list.append(min_mse_lasso)\n",
    "        lamda_lasso_list.append(min_lam_lasso)\n",
    "        \n",
    "    lamda_ridge_min = np.argmin(np.array(mse_ridge_list))\n",
    "    mse_ridge_min = np.min(mse_ridge_list)    \n",
    "    degree_ridge_min = np.argmin(np.array(mse_ridge_list)) + 1\n",
    "    \n",
    "    lamda_lasso_min = np.argmin(np.array(mse_lasso_list))\n",
    "    mse_lasso_min = np.min(mse_lasso_list)\n",
    "    degree_lasso_min = np.argmin(np.array(mse_lasso_list)) + 1\n",
    "    \n",
    "    \n",
    "    print('-'*25+'Ridge'+'-'*25)\n",
    "    print('Best Degree = %s'%degree_ridge_min)\n",
    "    print('Min MSE in Degree %s = %s'%(degree_ridge_min,mse_ridge_min))\n",
    "    print('Lamda for Min MSE = %s'%lamda_ridge_list[lamda_ridge_min])\n",
    "    choose_hyper_param(X, y, n, degree_ridge_min, lam_min, lam_max, True, True)\n",
    "\n",
    "    \n",
    "    print('-'*25+'Lasso'+'-'*25)\n",
    "    print('Best Degree = %s'%degree_lasso_min)\n",
    "    print('Min MSE in Degree %s = %s'%(degree_lasso_min,mse_lasso_min))\n",
    "    print('Lamda for Min MSE = %s'%lamda_lasso_list[lamda_lasso_min])\n",
    "    choose_hyper_param(X, y, n, degree_lasso_min, lam_min, lam_max, False, True)\n",
    "    \n",
    "    return lamda_ridge_list[lamda_ridge_min], lamda_lasso_list[lamda_lasso_min], mse_ridge_min, mse_lasso_min, degree_ridge_min, degree_lasso_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Ridge-------------------------\n",
      "Best Degree = 2\n",
      "Min MSE in Degree 2 = 0.5389005082633005\n",
      "Lamda for Min MSE = 10\n",
      "-------------------------Lasso-------------------------\n",
      "Best Degree = 2\n",
      "Min MSE in Degree 2 = 0.5377687045346315\n",
      "Lamda for Min MSE = 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEMCAYAAADK231MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgKklEQVR4nO3deXxU9b3/8dcnkwRICGtCUPYlYbGCxQguFcV7tdSl2lqttlVb7aW25T4ev/u7XbTLtbfL7a12u73aH7XW0tqq1+tKrxT1FgSX2gJWESQLIpuYhUWYJGT//P7IhE5jApMwM2dm8n4+mMfknPM9mc/J5PHO4Tvf8z3m7oiISObKCroAERFJLAW9iEiGU9CLiGQ4Bb2ISIZT0IuIZDgFvYhIhlPQi0SY2TIz+/oxtruZTU9mTSLxYBpHLwOJme0AioF2oB5YBSx19/oY9nWgxN23JbRIkTjTGb0MRJe5+1DgNOC9wK3BliOSWAp6GbDcvRp4is7Ax8yWm9m3u7ab2RfN7G0z22tmN0bva2ajzex3ZnbYzNab2bfN7Pmo7TPN7BkzO2BmFWZ2dZIOS+RdFPQyYJnZeOADwLu6YsxsMfAF4EKgBPj7bk3uAhqAscANkUfXvvnAM8D9wBjgWuCnZnZK/I9C5PgU9DIQPW5mYWA3UAvc1kObq4Ffuvtmd28AvtG1wcxCwJXAbe7e6O6vA7+K2vdSYIe7/9Ld29z9ZeAR4COJORyRY1PQy0B0hbsXAOcDM4HCHtqcTOcfgi47o74uArK7bY/+ehKwwMze6XoAH6fz7F8k6RT0MmC5+1pgOfD9Hja/DUyIWp4Y9XUd0AaMj1oX3XY3sNbdR0Q9hrr7Z+NTuUjfKOhloPsxcKGZndZt/UPAJ81stpnlEdW94+7twKPAN8wsz8xmAtdH7fs/QKmZXWdmOZHHGWY2K6FHItILBb0MaO5eB/wa+Hq39b+n84/Aajo/rF3dbdelwHCgGrgPeABojuwbBi4CrgH2Rtp8DxiUoMMQOSZdMCUSB2b2PWCsu99w3MYiSaYzepF+iIyTn2Od5gM3AY8FXZdIT7KDLkAkTRXQ2V1zMp1DNH8APBFoRSK9UNeNiEiGU9eNiEiGU9CLiGS4lOyjLyws9MmTJwddhohI2ti4ceM+dy/qaVtKBv3kyZPZsGFD0GWIiKQNM9vZ2zZ13YiIZDgFvYhIhlPQi4hkOAW9iEiGU9CLiGQ4Bb2ISIZLyeGVIiJBcHc6HFrbO2jrcNrbndaODtranbbo5w6nrd2Ptuta397ROaXM0YllvOspsr5r2f9mM11T0eRmZ3H+jDFxPy4FvYgMOK3tHby5r4Gtbx+mvDpMeeS5+nATQU7/VTh0EBu+1v0+9CdOQS8iGa0u3Ex59WHK3w6zNfK8rbaelvYOAHJCxrSioZw5dTTjRgwhJ5RFdsjICRmhrCxyQkZ2Vue67CwjO5RFTpYRyrKjbbu+zjLDrPN1I09YZMVfl7u2298sA2SHohbiSEEvIhmhvcOPBnp59WG2Rp731bccbVM8bBAzxw7j3NJCZo0dxsyTCphaOJTc7Mz+uFJBLyJpz935/G9fZtWWagAGZWdRWlzAohljmHnSMGaNLWDmScMYlZ8bcKXBUNCLSNpb8epeVm2p5jPnTeWq0ycweXQe2aHMPkvvCwW9iKS1Aw0t/OvvXue0CSP40vtnEspKTD93OtOfPBFJa9/83RbCTa1878o5CvleKOhFJG2tKa/l8Vf28rnzpzNjbEHQ5aQsBb2IpKX65ja++thrlIwZyucWTQu6nJSmPnoRSUu3ryrn7cNNPPLZsxmUHQq6nJSmM3oRSTvrdxzgvpd28smzJzNv4sigy0l5CnoRSStNre18+ZFNjBsxhC9cNCPoctKCum5EJK3cuXob2+sa+PWN88kfpAiLhc7oRSRtvL73MMvWvsGV88azsLQo6HLShoJeRNJCW3sHX35kEyPycvj6pbOCLiet6P89IpIWfvH8m7z21iHu+tg8RuQNzDlr+ktn9CKS8nbsa+CHz1Ry0exiLj51bNDlpB0FvYikNHfnlkc3kZudxbeueM/R+d0ldgp6EUlpD67fzUvbD/CVi2dRPGxw0OWkJQW9iKSs6kNN/NuTWzlr6miuOWNC0OWkrZiC3swWm1mFmW0zs1t62P5FM3sl8thsZu1mNiqybYeZvRbZtiHeByAimcnd+foTm2lp7+C7Hz5VXTYn4LijbswsBNwFXAjsAdab2Qp3f72rjbvfAdwRaX8Z8E/ufiDq2yxy931xrVxEMtrK16p55vUavnLxTCYX5gddTlqL5Yx+PrDN3be7ewvwIHD5MdpfCzwQj+JEZGA62NDCbSs2c+q44dx4zpSgy0l7sQT9OGB31PKeyLp3MbM8YDHwSNRqB542s41mtqS3FzGzJWa2wcw21NXVxVCWiGSqbz+5lXcaO28molsCnrhYfoI9dYx5L20vA17o1m1zjrvPAz4AfN7MFva0o7vf7e5l7l5WVKRLm0UGqrWVdTzy8h5uPm8as08eFnQ5GSGWoN8DRH/cPR7Y20vba+jWbePueyPPtcBjdHYFiYi8S0NzG1959DWmFuWz9ILpQZeTMWIJ+vVAiZlNMbNcOsN8RfdGZjYcOA94ImpdvpkVdH0NXARsjkfhIpJ5vv90BXsPHeH2K+cwOEc3E4mX4466cfc2M1sKPAWEgHvdfYuZ3RzZvizS9EPA0+7eELV7MfBYZFhUNnC/u6+K5wGISGbYuPMgy1/cwXVnTqJs8qigy8koMU1q5u4rgZXd1i3rtrwcWN5t3XZg7glVKCIDws/WvkHh0EF8afHMoEvJOPo4W0RSQnl1mPlTRjFUNxOJOwW9iASusaWNXQcamVFcEHQpGUlBLyKB21ZbD0Bp8dCAK8lMCnoRCVxlTWfQl+iMPiEU9CISuMqaMLmhLCaNygu6lIykoBeRwFXWhJk2ZqimO0gQ/VRFJHBVNfXqn08gBb2IBCrc1Mpb7xyhVP3zCaOgF5FAVR0dcaOgTxQFvYgEqqomDGhoZSIp6EUkUBXV9QzOyWLCSI24SRQFvYgEqqo2TMmYArKydE/YRFHQi0igKmvClKjbJqEU9CISmEONrdQcbtYHsQmmoBeRwFTWdn4Qq8nMEktBLyKBqYyMuFHXTWIp6EUkMJXVYfJzQ4wbMSToUjKagl5EAlNZU09JcQGR241KgijoRSQwVbVhXSiVBAp6EQnE/vpm9tW3aMRNEijoRSQQXTcbUdAnnoJeRAJRVds1x42CPtEU9CISiIrqMAWDsykeNijoUjKegl5EAlFVU88MjbhJCgW9iCSdu1NZG9bNwJNEQS8iSVcXbuadxlYNrUwSBb2IJF3XiBvNcZMcCnoRSbq/znGjoE8GBb2IJF1lTZiReTkUDs0NupQBQUEvIklXWROmVCNukkZBLyJJ5e5U1dTrQqkkUtCLSFJVH24i3NymETdJFFPQm9liM6sws21mdksP279oZq9EHpvNrN3MRsWyr4gMLBXVmvog2Y4b9GYWAu4CPgDMBq41s9nRbdz9Dnc/zd1PA24F1rr7gVj2FZGBpUqTmSVdLGf084Ft7r7d3VuAB4HLj9H+WuCBfu4rIhmusiZM4dBBjMzXiJtkiSXoxwG7o5b3RNa9i5nlAYuBR/qx7xIz22BmG+rq6mIoS0TSUWVNmBlj1T+fTLEEfU/jn7yXtpcBL7j7gb7u6+53u3uZu5cVFRXFUJaIpJuODqeqtp6SMeq2SaZYgn4PMCFqeTywt5e21/DXbpu+7isiGe6td47Q2NKu/vkkiyXo1wMlZjbFzHLpDPMV3RuZ2XDgPOCJvu4rIgND19QH6rpJruzjNXD3NjNbCjwFhIB73X2Lmd0c2b4s0vRDwNPu3nC8feN9ECKSHromM5uurpukOm7QA7j7SmBlt3XLui0vB5bHsq+IDExVNWHGDhvM8CE5QZcyoOjKWBFJmoqaMKVjdTafbAp6EUmK9g5nW209pWPUP59sCnoRSYrdBxppbuvQiJsAKOhFJCkqIiNu1HWTfAp6EUmKqq67SqnrJukU9CKSFJU19YwbMYT8QTEN9pM4UtCLSFJ0znGjbpsgKOhFJOHa2jvYXtdAiW42EggFvYgk3I79jbS0d1CqK2IDoaAXkYTrmuNGQyuDoaAXkYSrrAljBtM14iYQCnoRSbiqmnomjspjSG4o6FIGJAW9iCRcRU1YNxsJkIJeRBKqpa2DHfsaNAd9gBT0IpJQb+5roK3D9UFsgBT0IpJQFUenPlDQB0VBLyIJVVUTJpRlTC3KD7qUAUtBLyIJVVkTZtLoPAbnaMRNUBT0IpJQlTX1uiI2YAp6EUmYptZ2du5v0Bz0AVPQi0jCvFFXT4dDqSYzC5SCXkQSRnPcpAYFvYgkTGVNPTkhY/JojbgJkoJeRBKmqibMlMJ8crMVNUHST19EEqaiJkyJum0Cp6AXkYRobGlj94EjzFDQB05BLyIJsa22HtCIm1SgoBeRhKiojsxxozP6wCnoRSQhqmrryc3OYtKovKBLGfAU9CKSEJU1YaYVDSU7pJgJmt4BEUmIyuqw+udThIJeROIu3NTK3kNNuiI2RSjoRSTuqo6OuFHQp4KYgt7MFptZhZltM7Nbemlzvpm9YmZbzGxt1PodZvZaZNuGeBUuIqmrsrprjht13aSC7OM1MLMQcBdwIbAHWG9mK9z99ag2I4CfAovdfZeZjen2bRa5+774lS0iqayypp7BOVlMGKkRN6kgljP6+cA2d9/u7i3Ag8Dl3dp8DHjU3XcBuHttfMsUkXRSVRumZEwBWVkWdClCbEE/Dtgdtbwnsi5aKTDSzJ41s41mdn3UNgeejqxf0tuLmNkSM9tgZhvq6upirV9EUlBFdZgSddukjON23QA9/Un2Hr7P6cDfAUOAP5rZS+5eCZzj7nsj3TnPmFm5u6971zd0vxu4G6CsrKz79xeRNHGosZXacLPmuEkhsZzR7wEmRC2PB/b20GaVuzdE+uLXAXMB3H1v5LkWeIzOriARyVCVtbrZSKqJJejXAyVmNsXMcoFrgBXd2jwBnGtm2WaWBywAtppZvpkVAJhZPnARsDl+5YtIqvnrHDfqukkVx+26cfc2M1sKPAWEgHvdfYuZ3RzZvszdt5rZKmAT0AHc4+6bzWwq8JiZdb3W/e6+KlEHIyLBq6oJk58bYtyIIUGXIhGx9NHj7iuBld3WLeu2fAdwR7d124l04YjIwFBZU09JcQGREzxJAboyVkTiqrJGc9ykGgW9iMTN/vpm9je06IPYFKOgF5G4qazRHDepSEEvInFTWaOhlalIQS8icVNZE2bY4GyKhw0KuhSJoqAXkbipqqmnVCNuUo6CXkTiwt2pqAnrZuApSEEvInFRF27m0JFWZmhoZcpR0ItIXGjETepS0ItIXFTUdM1xo6BPNQp6EYmLqpowo/JzKRyaG3Qp0o2CXkTi4s87DvCeccM14iYFKehF5ITt3N/A9roGFs0oCroU6YGCXkRO2JryzttEL5oxJuBKpCcKehE5Yasr6phamM/kwvygS5EeKOhF5IQ0trTx0vb9LJqps/lUpaAXkRPy4rb9tLR1qNsmhSnoReSErKmoJT83xBlTRgZdivRCQS8i/eburCmv5ZzphQzKDgVdjvRCQS8i/VZZU8/eQ01coP75lKagF5F+Wx0ZVnm++udTmoJeRPptTUUts08axtjhg4MuRY5BQS8i/XKosZWNOw+yaKauhk11CnoR6ZfnttXR3uEaVpkGFPQi0i+ry2sZkZfDeydqWGWqU9CLSJ91dDhrK+pYWFJEKEuzVaY6Bb2I9Nmmtw6xv6FFwyrThIJeRPpsTXktZrCwVB/EpgMFvYj02bMVtbx3wghG5etuUulAQS8ifVIXbubVPYc02iaNKOhFpE/WVtYBaFriNKKgF5E+WVNey5iCQZxy8rCgS5EYxRT0ZrbYzCrMbJuZ3dJLm/PN7BUz22Jma/uyr4ikh9b2DtZV1bFoxhjdBDyNZB+vgZmFgLuAC4E9wHozW+Hur0e1GQH8FFjs7rvMbEys+4pI+ti48yDhpjZNe5BmYjmjnw9sc/ft7t4CPAhc3q3Nx4BH3X0XgLvX9mFfEUkTaypqyQkZ50wvDLoU6YNYgn4csDtqeU9kXbRSYKSZPWtmG83s+j7sC4CZLTGzDWa2oa6uLrbqRSSp1pTXcsbkURQMzgm6FOmDWIK+p44477acDZwOXAK8H/i6mZXGuG/nSve73b3M3cuKivTfQpFUs+dgI5U19boaNg0dt4+ezrPwCVHL44G9PbTZ5+4NQIOZrQPmxriviKSBNRWd/9PWTUbSTyxn9OuBEjObYma5wDXAim5tngDONbNsM8sDFgBbY9xXRNLAs+W1TByVx7Si/KBLkT467hm9u7eZ2VLgKSAE3OvuW8zs5sj2Ze6+1cxWAZuADuAed98M0NO+CToWEUmQptZ2XnhjHx8tm6BhlWkolq4b3H0lsLLbumXdlu8A7ohl30S54AfP0tzakYyXkuMwizwwunLBADPr/OCmh3VmkJ2VRW52FoOysxiUE2JQdtRydijy3Pv2SaPzmDN+hKbOjbOXtu+nqbVDV8OmqZiCPl0smDKa1nYFfVA88jG740T+4ZGVHtnete7oJ/Le2d69c3tbh9Pc1k5zWweHj7TS3NbRudzaQUt7B82t7ZF1vb/Pw4fk8L6SQs4rKWJhaZHuZxoHa8prGZyTxZlTRwddivRDRgX9dz98atAlSJK4O63tf/2j0NLWwZHWdrbsPcy6yjrWVdbx5Ka3AZhRXMDC0kLOKx1D2eSRDM4JBVx9enF31lTUcc60Qv3s0lRGBb0MHGZGbraRm51FQdT6aUVD+eDck3F3yqvDnaFfVcevXtzJz5978+hZ6XmlnWf7Uwvz1ed8HG/UNbDrQCP/sHBq0KVIPynoJSOZGbNOGsask4bxmfOm0djSxkvb97Ouch9rK+v41991zsIxfuQQFpYWsbCkiHOmj9aFQD14tqLzQvdFM3R9S7pS0MuAkJebzQUzi7lgZjEAu/Y3sraqs4vnib+8xf1/2kV2lnHj+6bwlYtnBVxtalldXktp8VDGj8wLuhTpJwW9DEgTR+dx3ehJXHfmJFraOnh510F++6dd3L1uO2dMHsWFs4uDLjElhJtaWb/jADe+b0rQpcgJUNDLgJeb3dlvP2/iSLbV1nPro5uYN3Eho4cOCrq0wL2wbR+t7a67SaU53XhEJCI3O4sffXQuh4+08dXHNh8dGjqQrSmvo2BwNqdPGhl0KXICFPQiUWaOHcY/XVjKqi3VPP7KW0GXE6jOYZW1LCwpIiekqEhnevdEulmycCqnTxrJvzyxhb3vHAm6nMBs2XuY2nCzrobNAAp6kW5CWcYPrppLW7vz5Uc2DdgunK5hleeValhlulPQi/RgcmE+X71kFs9V7eM3L+0MupxArC6vZe744RQV6EPpdKegF+nFxxdMZGFpEd9ZuZU39zUEXU5SHWho4S+739Hc8xlCQS/SCzPj9ivnkBvK4p8feoW2ATRh3rrKOtzR3aQyhIJe5BjGDh/Mt654Dy/veoefrdsedDlJs6ailtH5uZw6bnjQpUgcKOhFjuODc0/m4lPH8uP/reT1vYeDLifh2juctZV1nDejiCzN658RFPQix2FmfPuKUxk+JJf/+9ArNLe1B11SQr2y+yDvNLaq2yaDKOhFYjAqP5fvXXkq5dVhfvy/VUGXk1Cry2sJZRnnlmhYZaZQ0IvE6O9mFfPRsgn8bO0bbNx5IOhyEmZNeR2nTxrJ8CGasjlTKOhF+uBrl87ipOFD+OeHXqWxpS3ocuKu+lATr799WJOYZRgFvUgfFAzO4ftXzWXH/ka+u7I86HLirutqWPXPZxYFvUgfnTVtNDe9bwr3vbSTdZV1QZcTV6vLazl5+GBKi4cGXYrEkYJepB+++P4ZTB8zlC89vIlDja1BlxMXzW3tvLBtH4tmjtF9dDOMgl6kHwbnhPjh1XOpq2/mG7/bEnQ5cbH+zYM0tLSrfz4DKehF+mnO+BEsXTSdx/7yFr9/7e2gyzkh4aZWHli/i9zsLM6ePjrociTOdCtBkROw9ILprC6v5SuPvUbZ5FFpN9Pj7gON/OrFHTy4fjf1zW1cf9Yk8nIVC5lG76jICcgJZfHDq+dyyX8+z62PvsbPrz89Lfq3N+48yL3Pv8nvN79NlhmXzDmJm943hTnjRwRdmiSAgl7kBJUUF/Cl98/g209u5b837OHqMyYEXVKP2to7WLWlmnuee5NXdr/DsMHZLFk4jRvOnsRJw4cEXZ4kkIJeJA5uPGcKf9hay1cff40xwwal1Dzuh5ta+a8/72b5izt4650jTB6dxzcvP4Ur540nf5AiYCCwVLxNWllZmW/YsCHoMkT65NCRVq69+yXeqKvn1zfOZ8HUYD/U3LW/kV+++CYPrd9NQ0s7C6aM4tPnTuWCmWMIaVbKjGNmG929rMdtCnqR+Nlf38zVP/sjNYeb+e2nFzB3woikvr67s2HnQe55bjvPvF5DlhmXzT2Zm943hfdobvmMpqAXSaLqQ01c9bMXOXykjf/6zJnMHDssKa/7bEUtP3qmklf3HGL4kBw+vmAi1581mbHDByfl9SVYxwp6jaMXibOxwwdz/6fPZEhOiE/c82e219Un9PU6OpwfPVPJJ3+5nkNHWvnWFe/hj7dewJcWz1TICxBj0JvZYjOrMLNtZnZLD9vPN7NDZvZK5PEvUdt2mNlrkfU6TZcBYcKoPH7z6QW4O5+450/sOdiYkNcJN7Wy5L6N/Mcfqrhy3nhW/Z+FXHemxsLL3zpu0JtZCLgL+AAwG7jWzGb30PQ5dz8t8vhmt22LIut7/G+FSCaaPmYov75pPvXNbXz8nj9Re7gprt9/e109V9z1Amsqarntstl8/6o5DM4JxfU1JDPEckY/H9jm7tvdvQV4ELg8sWWJZIZTTh7O8hvnUxdu5hO/+BMHGlri8n1Xl9dw+Z0vcLCxld/ctIBPnTMlLS7UkmDEEvTjgN1Ry3si67o7y8xeNbPfm9kpUesdeNrMNprZkt5exMyWmNkGM9tQV5dZU7/KwDZv4kjuuaGMnfsbueHeP3O4qf+zXbo7d66u4qZfbWDi6DxWLD2Hs6Zpbho5tliCvqfThO5DdV4GJrn7XOA/gcejtp3j7vPo7Pr5vJkt7OlF3P1udy9z97KiIt2rUjLL2dMK+X+fmMfWtw9z0/L1/bo7VUNzG5/77ct8/+lKLp97Mg/ffDbjR+YloFrJNLEE/R4g+pru8cDe6Abuftjd6yNfrwRyzKwwsrw38lwLPEZnV5DIgHPBzGL+45r3snHnQT5z30aaWttj3nfHvgY+9NMXeGpLNV+7ZBY/+uhpDMlVf7zEJpagXw+UmNkUM8sFrgFWRDcws7EW6SA0s/mR77vfzPLNrCCyPh+4CNgczwMQSSeXzDmJ7105h+eq9vGPD/yF1vaO4+7zbEUtH7zzeWrDzfz6xgV8+typ6o+XPjnuGCx3bzOzpcBTQAi41923mNnNke3LgI8AnzWzNuAIcI27u5kVA49FfimzgfvdfVWCjkUkLVxVNoHGlnZuW7GFL/z3q/zw6tN6nJLA3Vm2dju3P1XOjOICfn59GRNGqatG+i6mwbaR7piV3dYti/r6TuDOHvbbDsw9wRpFMs4NZ0+moaWN21dVkJcb4t8+dOrfnKU3trTxxYc38eSmt7l0zknc/pE5Ghsv/abfHJGAfO786TQ0t3HXmjfIy83ma5fMwszYtb+RJfdtoKImzC0fmMlnFqqrRk6Mgl4kQF+4aAYNze384vk3yR+UzfzJo1j6wMt0dDjLPzWf80o1Ak1OnIJeJEBmxr9cOpvGljZ+8ocqzKBkzFDuvq6MyYX5QZcnGUJBLxKwrCzjux+eQ04oi6bWDr55+Sm6IYjElX6bRFJAKMv4zodODboMyVCaplhEJMMp6EVEMpyCXkQkwynoRUQynIJeRCTDKehFRDKcgl5EJMMp6EVEMpy5d79ZVPDMrA7YGXQd/VQI7Au6iBOg+oOl+oOVzvVPcvceJ0dKyaBPZ2a2wd3Lgq6jv1R/sFR/sNK9/t6o60ZEJMMp6EVEMpyCPv7uDrqAE6T6g6X6g5Xu9fdIffQiIhlOZ/QiIhlOQS8ikuEU9CIiGU5BnyRmNtHMVpjZvWZ2S9D19IeZnW9mz5nZMjM7P+h6+srMrjCzn5vZE2Z2UdD1xMLMpprZL8zs4aBr6S8zyzezjWZ2adC19JWZnRv5fb/HzF4Mup7+UtDHIBLOtWa2udv6xWZWYWbbYgjvUuBJd78RmJ2wYnsRp2NwoB4YDOxJVK09iUf97v64u/8D8Engowks95j6cizuvt3dbwqm0p714734MvBQcqvsXR9//s+5+83A/wC/CqLeuHB3PY7zABYC84DNUetCwBvAVCAXeJXOAD+Vzl+K6McYYDSwBlgNfCpNjyErsl8x8Nt0qz9qvx8A89Lh9ylq+8NB1XuC78XfA9fQ+cf10qBrP4Gf/0PAsKBr7+9DNwePgbuvM7PJ3VbPB7a5+3YAM3sQuNzdvwu867+oZvYF4LbI93oY+GWCy/4b8TiGKAeBQQkptBdxeg8M+Hfg9+7+coJL7lVfjgV4PcnlHVcf6x8K5NMZ+kfMbKW7dySz3u76+vM3s4nAIXc/nNxK40dB33/jgN1Ry3uABcdovwr4hpl9DNiRwLr6ok/HYGYfBt4PjADuTGhlsenre/CPdJ5hDjez6e6+LJHF9VGPx2Jmo4HvAO81s1sjf8RSUY/1u/tSADP7JLAv6JA/hmP9Lt1Ekk/M4k1B33/Ww7perz5z983ARxJXTr/09RgeBR5NXDl91tf6fwL8JHHlnJAej8Xd9wM3J7uYfjjme+Huy5NXSr/0Wr+735bkWuJOH8b23x5gQtTyeGBvQLX0V7ofQ7rXHy3dj0X1pzAFff+tB0rMbIqZ5dL5gdOKgGvqq3Q/hnSvP1q6H4vqT2VBfxqcDg/gAeBtoJXOv/w3RdZfDFTS+Wn9V4OuM5OPId3rz6RjUf3p99CkZiIiGU5dNyIiGU5BLyKS4RT0IiIZTkEvIpLhFPQiIhlOQS8ikuEU9CIiGU5BLyKS4RT0IiIZ7v8DvOMmepqr1WkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEMCAYAAADK231MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbhUlEQVR4nO3de5hU9Z3n8fe379DQXJtrg2DEKN61hTVo1MdLMINhzE3U2UyMMyzZIe7mmUvM7Gyys0meya7PZJ7EmGUdY8xOgjjjDVREcxk1XgI0ERW8IkLTXQgNdDW36vt3/+hqLIu+VHVX96lz+vN6nnroOud3qr4Hqj91+J3fOT9zd0REJLoKgi5ARESGloJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiTkEvIhJxCnoZUcxsl5ldHXQdIsNJQS8iEnEKehnxzGyCmT1hZg1m1pj8uSpl/ZfNbKeZHTGz983sluTy08zsOTNrMrMDZvZgyjafMLPNyXWbzewTQeybCCjoRaDr9+BnwCnAbCAB/BjAzMqBHwHXuftY4BPA1uR23wGeASYAVcBdyW0mAk8mt5sE/AB40swmDc/uiHyUgl5GPHc/6O4Pu/txdz8CfA+4PKVJJ3C2mY1y973uvj25vI2uL4cZ7t7s7i8kl/8R8K67/4u7t7v7A8BbwPXDtEsiH6GglxHPzEab2f81s91mdhh4HhhvZoXufgy4EVgB7DWzJ83sjOSmfwMYsMnMtpvZV5LLZwC7095mNzBz6PdG5GQKehH4S+DjwEJ3rwA+mVxuAO7+tLtfA0yn68j8n5PLP3D3P3f3GcB/An5iZqcBMbqO9FPNBuqHfE9EeqCgl5Go2MzKuh909bEngHiyf/3b3Q3NbKqZfSbZV98CHAU6kuu+kHLSthHw5Lr1wOlmdrOZFZnZjcB84Inh2kGRVAp6GYnW0xXs3Y/xwCjgAPB7YENK2wK6jvhjwCG6+u7/c3LdxcBGMzsKrAP+i7u/7+4HgSXJ7Q7S1cWzxN0PDO1uifTMNPGIiEi06YheRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQirijoAnoyefJknzNnTtBliIiExpYtWw64e2VP6/Iy6OfMmUNNTU3QZYiIhIaZpd924wR13YiIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIi4vh1eKhFF9PMEbscNBlyEhVlJUwOWn9zgUflAU9CI58vU1W9m061DQZUiITR5TSs3fXZ3z11XQi+TIroPHuHb+VG6/al7QpUhIFRbYkLyugl4kB1raO9h/pIX5Myo4e+a4oMsR+QidjBXJgQ+amgGYMX5UwJWInExBL5ID9fEEADMV9JKHFPQiORCL64he8peCXiQHYskj+unjygKuRORkCnqRHKhvTDB5TCllxYVBlyJyEgW9SA7EmhLMHK+jeclPCnqRHKiPJ9Q/L3lLQS8ySO5OLJ7QiBvJWwp6kUFqPN5Gc1unjuglbynoRQapvrFrxI2CXvKVgl5kkHSxlOQ7Bb3IIHWPoZ+hUTeSpxT0IoMUiycoKy5gYnlJ0KWI9EhBLzJIsaauoZVmQ3OLWZHBUtCLDFJ9o4ZWSn5T0IsMUn28mRnjFPSSvzIKejNbbGZvm9kOM7ujh/V/bWZbk49tZtZhZhOT63aZ2evJdTW53gGRIDW3dXDgaAszJyjoJX/1O8OUmRUCdwPXAHXAZjNb5+5vdLdx9zuBO5Ptrwe+7u6pk2de6e4Hclq5SB7QhCMSBpkc0S8Adrj7TndvBdYAS/tofxPwQC6KE8l39RpaKSGQSdDPBPakPK9LLjuJmY0GFgMPpyx24Bkz22JmywdaqEg+0sVSEgaZTA7e05gx76Xt9cCLad02i9w9ZmZTgF+Z2Vvu/vxJb9L1JbAcYPbs2RmUJRK87oulpmnCEcljmRzR1wGzUp5XAbFe2i4jrdvG3WPJP/cDj9LVFXQSd7/H3avdvbqysjKDskSCF4snmDK2lNIiTTgi+SuToN8MzDOzuWZWQleYr0tvZGbjgMuBtSnLys1sbPfPwLXAtlwULpIPYvFmnYiVvNdv1427t5vZSuBpoBC4z923m9mK5PpVyaY3AM+4+7GUzacCjyavGCwCVrv7hlzugEiQ6uMJ5k+vCLoMkT5l0kePu68H1qctW5X2/H7g/rRlO4HzBlWhSJ5yd+rjCa4+c0rQpYj0SVfGigzQwWOttLZrwhHJfwp6kQGKaWilhISCXmSANLOUhIWCXmSAdLGUhIWCXmSAYvFmRhUXMn50cdCliPRJQS8yQLF4gpkTNOGI5D8FvcgAdc8sJZLvFPQiA9Q1s5TucSP5T0EvMgDNbR0cPNaqmaUkFBT0IgMQi2topYSHgl5kAGLxrpmlNIWghIGCXmQAdFWshImCXmQA6uIJzGBqhU7GSv5T0IsMQPeEIyVF+hWS/KdPqcgAxOIJddtIaCjoRQYgFtfFUhIeCnqRLHV2OrF4s47oJTQU9CJZOnCshdYOTTgi4aGgF8lS9xh6Bb2EhYJeJEsaQy9ho6AXyZKCXsJGQS+SpbrGBOUlhVSMKgq6FJGMKOhFstQ9tFITjkhYKOhFshRrSuhmZhIqCnqRLMXizRpxI6GioBfJwvHWdg4da9WJWAkVBb1IFj4cQ6+7Vkp4KOhFsnBiZilNISghoqAXycKJMfQ6GSshoqAXyUIsnqBAE45IyCjoRbJQF08wtaKM4kL96kh46NMqkgXdh17CSEEvkgWNoZcwyijozWyxmb1tZjvM7I4e1v+1mW1NPraZWYeZTcxkW5Gw6Ox09jZpCkEJn36D3swKgbuB64D5wE1mNj+1jbvf6e7nu/v5wDeB59z9UCbbioRFw9EW2jqcmRpDLyGTyRH9AmCHu+9091ZgDbC0j/Y3AQ8McFuRvFXfPYZeR/QSMpkE/UxgT8rzuuSyk5jZaGAx8PAAtl1uZjVmVtPQ0JBBWSLDK6agl5DKJOh7uher99L2euBFdz+U7bbufo+7V7t7dWVlZQZliQwvXSwlYZVJ0NcBs1KeVwGxXtou48Num2y3FclrsXgzY0uLqCgrDroUkaxkEvSbgXlmNtfMSugK83XpjcxsHHA5sDbbbUXCoK5RY+glnPqdC83d281sJfA0UAjc5+7bzWxFcv2qZNMbgGfc/Vh/2+Z6J0SGQ9fFUhpxI+GT0aSX7r4eWJ+2bFXa8/uB+zPZViSMYk0JLpg9PugyRLKmK2NFMnCspZ348TadiJVQUtCLZGBvU3LEjfroJYQU9CIZqGvUGHoJLwW9SAY+nEJQQS/ho6AXyUAsnqCwwJg6tjToUkSypqAXyUAsnmBaRRlFmnBEQkifWpEM1GkMvYSYgl4kA5pZSsJMQS/Sj45O54MmzSwl4aWgF+lHw5EW2jtdY+gltBT0Iv3onnBEQS9hpaAX6YdmlpKwU9CL9OPDmaU06kbCSUEv0o9YPMHYsiLGasIRCSkFvUg/YvGE+ucl1BT0Iv2oa1TQS7gp6EX6oYulJOwU9CJ9ONLcxuHmdgW9hJqCXqQPe5u6bk+smaUkzBT0In348GIpDa2U8FLQi/ShXjNLSQQo6EX60D3hyJSxOqKX8FLQi/She8KRwgILuhSRAVPQi/QhFm/WiVgJPQW9SB/qdVWsRICCXqQX7R2dfHC4WTczk9BT0Iv0Yv+RFjo6XSNuJPQU9CK9iGnCEYkIBb1ILzSzlESFgl6kF91BP11BLyGnoBfpRSyeYNyoYsaUFgVdisigKOhFehGLN+tErERCRkFvZovN7G0z22Fmd/TS5goz22pm283suZTlu8zs9eS6mlwVLjLUNLOUREW//yc1s0LgbuAaoA7YbGbr3P2NlDbjgZ8Ai9291sympL3Mle5+IHdliwy9+niChXMnBl2GyKBlckS/ANjh7jvdvRVYAyxNa3Mz8Ii71wK4+/7clikyvA43t3FEE45IRGQS9DOBPSnP65LLUp0OTDCzZ81si5l9KWWdA88kly/v7U3MbLmZ1ZhZTUNDQ6b1iwyJ7jH0CnqJgkyGE/R02z7v4XUuAq4CRgEvm9nv3f0dYJG7x5LdOb8ys7fc/fmTXtD9HuAegOrq6vTXFxlWJy6W0g3NJAIyOaKvA2alPK8CYj202eDux5J98c8D5wG4eyz5537gUbq6gkTyWn08OYWgjuglAjIJ+s3APDOba2YlwDJgXVqbtcBlZlZkZqOBhcCbZlZuZmMBzKwcuBbYlrvyRYZGfWOC4kKjckxp0KWIDFq/XTfu3m5mK4GngULgPnffbmYrkutXufubZrYBeA3oBO51921mdirwqJl1v9dqd98wVDsjkiuxeIJp48oo0IQjEgEZXfLn7uuB9WnLVqU9vxO4M23ZTpJdOCJhEosnmDFO3TYSDboyVqQHsXhCJ2IlMhT0Imm6JxzRiViJCgW9SJoPDjfT6RpDL9GhoBdJE0sOrVTQS1Qo6EXSfDizlOaKlWhQ0IukqdftDyRiFPQiaerjCSaMLmZ0iSYckWhQ0IukicUTOpqXSFHQi6RR0EvUKOhFUrg79Y2aWUqiRUEvkuJwczvHWjsU9BIpCnqRFPWNGnEj0aOgF0nx4cxSGkMv0aGgF0kRa+q+WEpH9BIdCnqRFPXxBCWFBUzWhCMSIQp6kRSxeDPTx2vCEYkWBb1IivrG45pwRCJHQS+SIhZv1ogbiRwFvUhSW0cn+440a2YpiRwFvUjSB03NuOv2xBI9CnqRJN2eWKJKQS+SFFPQS0Qp6EWSTgS9Rt1IxCjoRZLq481MKi9hVElh0KWI5JSCXiSpXvehl4hS0IsAx1ra+cPuRs6YNjboUkRyTkEvAjz+aoyjLe3cePGsoEsRyTkFvQiwelMtp08dw0WnTAi6FJGcU9DLiPd6XROv1TVx84LZmOlmZhI9CnoZ8VZv2k1ZcQE3XFgVdCkiQ0JBLyPakeY21m6Ncf25Mxg3qjjockSGhIJeRrS1W2Mcb+3g5oWzgy5FZMhkFPRmttjM3jazHWZ2Ry9trjCzrWa23cyey2ZbkSC4O7/cWMuZ0ys4f9b4oMsRGTL9Br2ZFQJ3A9cB84GbzGx+WpvxwE+Az7j7WcAXMt1WJChb98R5c+9hblmok7ASbZkc0S8Adrj7TndvBdYAS9Pa3Aw84u61AO6+P4ttRQKxemMto0sKWXr+jKBLERlSmQT9TGBPyvO65LJUpwMTzOxZM9tiZl/KYluRYdeUaOPx12IsPX8GY8t0ElairSiDNj39n9Z7eJ2LgKuAUcDLZvb7DLftehOz5cBygNmzdWJMhtZjr9TT3NbJzQtOCboUkSGXyRF9HZB6XXgVEOuhzQZ3P+buB4DngfMy3BYAd7/H3avdvbqysjLT+kWy1nUSdjfnVo3jnKpxQZcjMuQyCfrNwDwzm2tmJcAyYF1am7XAZWZWZGajgYXAmxluKzKstuxu5J19R7l5gf7nKCNDv1037t5uZiuBp4FC4D53325mK5LrV7n7m2a2AXgN6ATudfdtAD1tO0T7IpKR1RtrGVNaxPXn6SSsjAyZ9NHj7uuB9WnLVqU9vxO4M5NtRYISP97KE6/v5cbqWZSXZvTxFwk9XRkrI8pDW+pobe/UlbAyoijoZcRwd1ZvquWC2eM5c3pF0OWIDBsFvYwYG98/xM6GYzoJKyOOgl5GjNUba6koK2LJuToJKyOLgl5GhINHW3hq214+e2EVo0oKgy5HZFgp6GVEeGhLHW0dzi06CSsjkIJeIq+z03lgUy0L5kxk3tSxQZcjMuwU9BJ5L+88yK6DxzWkUkYsBb1E3i837mbC6GIWnz0t6FJEAqGgl0jbf6SZZ7bv43MXVlFWrJOwMjIp6CXS/q2mjvZO5yZ128gIpqCXyOo+CXvJqZP4WOWYoMsRCYyCXiLr+XcbqGtM6CSsjHgKeoms1RtrmVRewqfO0klYGdkU9BJJ+w4385u39vOF6lmUFOljLiObfgMkkh7cvIeOTuemBbP6bywScQp6iZyOTmfNploumzeZUyaVB12OSOAU9BI5z769n1hTs+5rI5KkoJfIWb2xlsqxpVx15tSgSxHJCwp6iZT6eIJ/f3s/N1bPorhQH28RUNBLxDy4qRYHlukkrMgJCnqJjPaOTh6s2cMVp1dSNWF00OWI5A0FvUTGb97az77DLdy88JSgSxHJK0VBF5BLx1vbgy4Bwz763Hpp2Mv6AjMKzTAD629jOaGz07nvhfeZVlHGlR+vDLockbwSqaC/6Du/JtHWEXQZOVNgUFhgWDL8u37uWtb1ZWAUFpDyszFuVDFTK0qZUlHG1LFlTK0oZWpFWfJRyoTRJRQURO8L5P6XdrHx/UN894/PpkgnYUU+IlJB/1ef+jjtHZ2Bvb+nP/f09d7neug6Mu106HBP/uwpP3ddDNTpnvyzq32Hf7isKdFGfbyZV2rjHDzWetLrFxcaU8aWMaWi9MQXwZSUL4ILZk9gTGm4PhbbY018/6m3uPrMKRo7L9KDcP1G9+O2S+cGXUJeaWnvoOFIC/sOt7D/cDP7Djez70gL+w43s/9wCzsajvLiewc40vxhl9fM8aNY9ScXcU7VuAArz1yitYPbH3iF8aOL+d+fP0/dXSI9iFTQy0eVFhVSNWF0vyNQjre2dwX//qN8a+02PrfqJb679Gy+eHH+D1H8zpNvsPPAMX5x20ImlpcEXY5IXlJnpjC6pIg5k8u5ev5UHv/apVw8ZwJ/8/BrfPOR12lpz99zHhu27WX1xlqWf/JUFp02OehyRPKWgl4+YtKYUn5+6wK+esXHeGBTLV9c9TKxeCLosk6ytynBNx5+nXOrxvGX13w86HJE8pqCXk5SVFjANxafwao/uYj3Go6x5K4XeHHHgaDLOqGj0/mva7bS1tHJD5ddoPvNi/RDvyHSq8VnT2PtykVMKi/hP/50I//n2ffwnoYKDbNVz73HxvcP8fefOYu5k3UbYpH+KOilTx+rHMNjf7GI686Zzv/a8BYrfrGFI81tgdXzSm0jP/jVOyw5dzqfv6gqsDpEwiSjoDezxWb2tpntMLM7elh/hZk1mdnW5ONbKet2mdnryeU1uSxehkd5aRE/vukC/u6PzuTXb+5n6Y9f5N19R4a9jiPNbdy+5hWmVZTxvRvO0VBKkQz1G/RmVgjcDVwHzAduMrP5PTT9nbufn3z8z7R1VyaXVw++ZAmCmfFnl53KL/9sIYeb21h694s88VpsWGv41trt1Dcm+OGy8xk3qnhY31skzDI5ol8A7HD3ne7eCqwBlg5tWZKv/sOpk3jia5dxxrSxrFz9Ct994o1huRr50VfqePSVem6/ah7VcyYO+fuJREkmQT8T2JPyvC65LN0lZvaqmT1lZmelLHfgGTPbYmbLe3sTM1tuZjVmVtPQ0JBR8RKMaePKWLP8Ev70klO494X3ueXejTQcaRmy96s9eJz//th2Lp4zgZVXnjZk7yMSVZkEfU8doelDL/4AnOLu5wF3AY+lrFvk7hfS1fXzF2b2yZ7exN3vcfdqd6+urNTdB/NdSVEBf7/0bP7pxvN4tS7Okrt+x5bdjTl/n7aOTm5f8wpm8E83nq8blokMQCa/NXVA6rXwVcBHOmfd/bC7H03+vB4oNrPJyeex5J/7gUfp6gqSiLjhgioe+eoiSosKWXbPy/zgV+9w8Gjuju5/+Ot32bonzj989hxNJiIyQJkE/WZgnpnNNbMSYBmwLrWBmU2z5BAIM1uQfN2DZlZuZmOTy8uBa4FtudwBCd78GRU8vvJSrpk/lR/95l0u+f5v+cZDr/H2B4MbmfPyewe5+9kdfLG6iiXnzshRtSIjT783NXP3djNbCTwNFAL3uft2M1uRXL8K+DzwVTNrBxLAMnd3M5sKPJr8DigCVrv7hiHaFwnQuNHF/OSWi3h33xF+9tIuHvlDHQ/W7OGyeZP5yqK5XH56ZVb3wY8fb+XrD25l7qRyvn39Wf1vICK9sny40jFddXW119RoyH2YNR5rZfWmWv7fy7vYd7iFUyvLuXXRXD534UxGl/R9fOHurPjFFn771n4e+eqi0NwyWSRIZraltyHsCnoZUq3tnTy1bS8/feF9XqtrYtyoYm5aMJsvXXIKM8aP6nGb1Rtr+dtHX+dvP30Gyz/5sWGuWCScFPQSOHenZncj973wPk9v/wAz49PnTOe2S+dy/qzxJ9rt2H+EJXe9wMVzJvLzWxdEctpDkaHQV9Br4hEZFmbGxXMmcvGciew5dJyfv7SLBzfv4fFXY1w4ezy3XXoqV55Rydce2MrokiL+8QvnKeRFckRH9BKYoy3t/FvNHn724i5qDx1ndEkhx1s7+OmfVnPVmVODLk8kVHREL3lpTGkRty6ay5cumcNv3tzHv/x+NxfMnqCQF8kxBb0ErrDAuPasaVx71rSgSxGJJF1PLiIScQp6EZGIU9CLiEScgl5EJOIU9CIiEaegFxGJOAW9iEjEKehFRCIuL2+BYGYNwO6g6xigycCBoIsYBNUfLNUfrDDXf4q79zgPa14GfZiZWU1v95sIA9UfLNUfrLDX3xt13YiIRJyCXkQk4hT0uXdP0AUMkuoPluoPVtjr75H66EVEIk5H9CIiEaegFxGJOAW9iEjEKeiHiZnNNrN1Znafmd0RdD0DYWZXmNnvzGyVmV0RdD3ZMrM/NrN/NrO1ZnZt0PVkwsxONbOfmtlDQdcyUGZWbmZbzGxJ0LVky8wuS37e7zWzl4KuZ6AU9BlIhvN+M9uWtnyxmb1tZjsyCO/TgSfd/SvA/CErthc52gcHjgJlQN1Q1dqTXNTv7o+5+58DXwZuHMJy+5TNvrj7Tne/LZhKezaAf4tvAP86vFX2Lsu//9+5+wrgCeDnQdSbE+6uRz8P4JPAhcC2lGWFwHvAqUAJ8CpdAX4OXR+K1McUYBLw78BvgVtDug8Fye2mAr8MW/0p2/0jcGEYPk8p6x8Kqt5B/ltcDSyj68t1SdC1D+Lv/1+BiqBrH+hDk4NnwN2fN7M5aYsXADvcfSeAma0Blrr7PwAn/RfVzP4K+HbytR4CfjbEZX9ELvYhRSNQOiSF9iJH/wYGfB94yt3/MMQl9yqbfQHeGOby+pVl/WOAcrpCP2Fm6929czjrTZft37+ZzQaa3P3w8FaaOwr6gZsJ7El5Xgcs7KP9BuB/mNnNwK4hrCsbWe2DmX0W+BQwHvjxkFaWmWz/Db5G1xHmODM7zd1XDWVxWepxX8xsEvA94AIz+2bySywf9Vi/u68EMLMvAweCDvk+9PVZuo1hPjDLNQX9wFkPy3q9+szdtwGfH7pyBiTbfXgEeGToyslatvX/CPjR0JUzKD3ui7sfBFYMdzED0Oe/hbvfP3ylDEiv9bv7t4e5lpzTydiBqwNmpTyvAmIB1TJQYd+HsNefKuz7ovrzmIJ+4DYD88xsrpmV0HXCaV3ANWUr7PsQ9vpThX1fVH8+C/pscBgewAPAXqCNrm/+25LLPw28Q9fZ+v8WdJ1R3oew1x+lfVH94XvopmYiIhGnrhsRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGI+/988Z09mkuOZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lamda_ridge_min, lamda_lasso_min, mse_ridge_min, mse_lasso_min, degree_ridge_min, degree_lasso_min = choose_degree(X, y, 5, 4, -10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ridge Regression with using degree 2 polynomial expansion and lambda = 10.0000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.4956\n",
      "MSE (Testing)  = 0.5122\n",
      "\n",
      "\n",
      "For Lasso with using degree 2 polynomial expansion and lambda = 0.0010\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.4966\n",
      "MSE (Testing)  = 0.5101\n"
     ]
    }
   ],
   "source": [
    "# So we can use the best degree : 2\n",
    "# The best lamda for ridge : 10\n",
    "# The best lamda for lasso : 0.001\n",
    "# to find the Bias of trianing data and Varaince of testing data.\n",
    "\n",
    "# 1. split the data (X, y) into training data (X_train, y_train) and test data (X_test, y_test)\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, 0.8)\n",
    "\n",
    "# 2. standardize the training data and do the same transformation to the test data\n",
    "s = StandardScaler()\n",
    "s.fit(X_train)\n",
    "X_train = s.transform(X_train)\n",
    "s_mean = s.mean_\n",
    "s_scale = s.scale_\n",
    "X_test = (X_test-s_mean)/s_scale\n",
    "\n",
    "# 3. expand the basis of the training data and test data\n",
    "X_train = expand_basis(X_train, 2)\n",
    "X_test = expand_basis(X_test, 2)\n",
    "\n",
    "# 4. standardize the training data again and do the same transformation to the test data\n",
    "s.fit(X_train)\n",
    "X_train_final = s.transform(X_train)\n",
    "s_mean = s.mean_\n",
    "s_scale = s.scale_\n",
    "X_test_final = (X_test-s_mean)/s_scale\n",
    "\n",
    "# ridge\n",
    "ridge_reg_final = Ridge(alpha = lamda_ridge_min)\n",
    "\n",
    "ridge_predict_train_final = ridge_reg_final.fit(X_train_final,y_train).predict(X_train_final)\n",
    "mse_ridge_train_final = np.dot((y_train - ridge_predict_train_final).T,(y_train - ridge_predict_train_final))/(len(y_train))\n",
    "\n",
    "ridge_predict_test_final = ridge_reg_final.fit(X_train_final,y_train).predict(X_test_final)\n",
    "mse_ridge_test_final = np.dot((y_test - ridge_predict_test_final).T,(y_test - ridge_predict_test_final))/(len(y_test))\n",
    "\n",
    "lasso_reg_final = Lasso(alpha = lamda_lasso_min)\n",
    "\n",
    "lasso_predict_train_final = lasso_reg_final.fit(X_train_final,y_train).predict(X_train_final)\n",
    "mse_lasso_train_final = np.dot((y_train - lasso_predict_train_final).T,(y_train - lasso_predict_train_final))/(len(y_train))\n",
    "\n",
    "lasso_predict_test_final = lasso_reg_final.fit(X_train_final,y_train).predict(X_test_final)\n",
    "mse_lasso_test_final = np.dot((y_test - lasso_predict_test_final).T,(y_test - lasso_predict_test_final))/(len(y_test))\n",
    "\n",
    "\n",
    "print('For Ridge Regression with using degree %d polynomial expansion and lambda = %.4f' % (2, lamda_ridge_min))\n",
    "print('--------------------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_ridge_train_final)\n",
    "print('MSE (Testing)  = %.4f' % mse_ridge_test_final)\n",
    "\n",
    "print('\\n\\nFor Lasso with using degree %d polynomial expansion and lambda = %.4f' % (2, lamda_lasso_min))\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_lasso_train_final)\n",
    "print('MSE (Testing)  = %.4f' % mse_lasso_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP96ktvsOI4PiuW52tcNLjx",
   "collapsed_sections": [],
   "name": "Practical1_starter.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
